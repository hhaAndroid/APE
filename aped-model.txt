SomeThing(
  (model_vision): DeformableDETRSegmVL(
    (backbone): SimpleFeaturePyramid(
      (simfp_2): Sequential(
        (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
        (1): LayerNorm()
        (2): GELU(approximate='none')
        (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))
        (4): Conv2d(
          256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): LayerNorm()
        )
        (5): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): LayerNorm()
        )
      )
      (simfp_3): Sequential(
        (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
        (1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): LayerNorm()
        )
        (2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): LayerNorm()
        )
      )
      (simfp_4): Sequential(
        (0): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): LayerNorm()
        )
        (1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): LayerNorm()
        )
      )
      (simfp_5): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): LayerNorm()
        )
        (2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): LayerNorm()
        )
      )
      (net): ViT(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
        )
        (rope_win): VisionRotaryEmbeddingFast()
        (rope_glb): VisionRotaryEmbeddingFast()
        (blocks): ModuleList(
          (0): Block(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q_proj): Linear(in_features=1024, out_features=1024, bias=False)
              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (inner_attn_ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (rope): VisionRotaryEmbeddingFast()
            )
            (drop_path): Identity()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): SwiGLU(
              (w1): Linear(in_features=1024, out_features=2730, bias=True)
              (w2): Linear(in_features=1024, out_features=2730, bias=True)
              (act): SiLU()
              (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)
              (w3): Linear(in_features=2730, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1-23): 23 x Block(
            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q_proj): Linear(in_features=1024, out_features=1024, bias=False)
              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)
              (v_proj): Linear(in_features=1024, out_features=1024, bias=False)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (inner_attn_ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
              (proj): Linear(in_features=1024, out_features=1024, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (rope): VisionRotaryEmbeddingFast()
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): SwiGLU(
              (w1): Linear(in_features=1024, out_features=2730, bias=True)
              (w2): Linear(in_features=1024, out_features=2730, bias=True)
              (act): SiLU()
              (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)
              (w3): Linear(in_features=2730, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (top_block): LastLevelMaxPool()
    )
    (position_embedding): PositionEmbeddingSine()
    (neck): ChannelMapper(
      (convs): ModuleList(
        (0-4): 5 x ConvNormAct(
          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (transformer): DeformableDetrTransformerVL(
      (encoder): DeformableDetrTransformerEncoderVL(
        (layers): ModuleList(
          (0-5): 6 x BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)
                (attention_weights): Linear(in_features=256, out_features=160, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activation): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=2048, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=2048, out_features=256, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (norms): ModuleList(
              (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (vl_layers): ModuleList(
          (0-5): 6 x VisionLanguageFusion(
            use_checkpoint=True
            (b_attn): BiAttentionBlock(
              (layer_norm_v): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (layer_norm_l): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
              (attn): BiMultiHeadAttention(
                stable_softmax_2d=True
                clamp_min_for_underflow=True
                clamp_max_for_overflow=True
                use_attention_mask_v=False
                (v_proj): Linear(in_features=256, out_features=2048, bias=True)
                (l_proj): Linear(in_features=1024, out_features=2048, bias=True)
                (values_v_proj): Linear(in_features=256, out_features=2048, bias=True)
                (values_l_proj): Linear(in_features=1024, out_features=2048, bias=True)
                (out_v_proj): Linear(in_features=2048, out_features=256, bias=True)
                (out_l_proj): Linear(in_features=2048, out_features=1024, bias=True)
              )
              (drop_path): Identity()
            )
          )
        )
      )
      (decoder): DeformableDetrTransformerDecoderVL(
        (layers): ModuleList(
          (0-5): 6 x BaseTransformerLayer(
            (attentions): ModuleList(
              (0): MultiheadAttention(
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
                )
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
              (1): MultiScaleDeformableAttention(
                (dropout): Dropout(p=0.0, inplace=False)
                (sampling_offsets): Linear(in_features=256, out_features=320, bias=True)
                (attention_weights): Linear(in_features=256, out_features=160, bias=True)
                (value_proj): Linear(in_features=256, out_features=256, bias=True)
                (output_proj): Linear(in_features=256, out_features=256, bias=True)
              )
            )
            (ffns): ModuleList(
              (0): FFN(
                (activation): ReLU(inplace=True)
                (layers): Sequential(
                  (0): Sequential(
                    (0): Linear(in_features=256, out_features=2048, bias=True)
                    (1): ReLU(inplace=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (1): Linear(in_features=2048, out_features=256, bias=True)
                  (2): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (norms): ModuleList(
              (0-2): 3 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (bbox_embed): ModuleList(
          (0-6): 7 x MLP(
            (layers): ModuleList(
              (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
        )
        (class_embed): ModuleList(
          (0-5): 6 x VisionLanguageAlign(
            (dot_product_projection_image): Identity()
            (dot_product_projection_text): Linear(in_features=1024, out_features=256, bias=True)
          )
          (6): Linear(in_features=256, out_features=1, bias=True)
        )
        (bbox_embed_ambiguous): ModuleList(
          (0): MLP(
            (layers): ModuleList(
              (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
              (2): Linear(in_features=256, out_features=4, bias=True)
            )
          )
        )
        (class_embed_ambiguous): ModuleList(
          (0): Linear(in_features=256, out_features=1, bias=True)
        )
      )
      (enc_output): Linear(in_features=256, out_features=256, bias=True)
      (enc_output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (pos_trans): Linear(in_features=512, out_features=512, bias=True)
      (pos_trans_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (pix_trans): Linear(in_features=256, out_features=256, bias=True)
      (pix_trans_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (bbox_embed): ModuleList(
      (0-6): 7 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=4, bias=True)
        )
      )
    )
    (criterion): ModuleList(
      (0): Criterion DeformableCriterion
          matcher: Matcher HungarianMatcher
              cost_class: 2.0
              cost_bbox: 5.0
              cost_giou: 2.0
              cost_class_type: focal_loss_cost
              focal cost alpha: 0.25
              focal cost gamma: 2.0
          matcher_stage1: Matcher Stage1Assigner
              training: False
              positive_fraction: 0.5
              batch_size_per_image: 256
              k: 4
              t_low: 0.3
              t_high: 0.7
              anchor_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd54bd60>
          matcher_stage2: Matcher Stage2Assigner
              training: False
              positive_fraction: 0.25
              num_classes: 1256
              batch_size_per_image: 900
              proposal_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd672370>
              k: 4
          losses: ['class', 'boxes', 'masks']
          loss_class_type: focal_loss
          weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_mask': 5, 'loss_dice': 5, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_mask_0': 5, 'loss_dice_0': 5, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_mask_1': 5, 'loss_dice_1': 5, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_mask_2': 5, 'loss_dice_2': 5, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_mask_3': 5, 'loss_dice_3': 5, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_mask_4': 5, 'loss_dice_4': 5, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0, 'loss_mask_enc': 5, 'loss_dice_enc': 5}
          num_classes: 1256
          eos_coef: 0.1
          focal loss alpha: 0.25
          focal loss gamma: 2.0
          use_fed_loss: True
          fed_loss_num_classes: 50
      (1): Criterion DeformableCriterion
          matcher: Matcher HungarianMatcher
              cost_class: 2.0
              cost_bbox: 5.0
              cost_giou: 2.0
              cost_class_type: focal_loss_cost
              focal cost alpha: 0.25
              focal cost gamma: 2.0
          matcher_stage1: Matcher Stage1Assigner
              training: False
              positive_fraction: 0.5
              batch_size_per_image: 256
              k: 4
              t_low: 0.3
              t_high: 0.7
              anchor_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd672550>
          matcher_stage2: Matcher Stage2Assigner
              training: False
              positive_fraction: 0.25
              num_classes: 365
              batch_size_per_image: 900
              proposal_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd56d2b0>
              k: 4
          losses: ['class', 'boxes', 'masks']
          loss_class_type: focal_loss
          weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_mask': 5, 'loss_dice': 5, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_mask_0': 5, 'loss_dice_0': 5, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_mask_1': 5, 'loss_dice_1': 5, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_mask_2': 5, 'loss_dice_2': 5, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_mask_3': 5, 'loss_dice_3': 5, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_mask_4': 5, 'loss_dice_4': 5, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0, 'loss_mask_enc': 5, 'loss_dice_enc': 5}
          num_classes: 365
          eos_coef: 0.1
          focal loss alpha: 0.25
          focal loss gamma: 2.0
          use_fed_loss: False
          fed_loss_num_classes: 50
      (2): Criterion DeformableCriterion
          matcher: Matcher HungarianMatcher
              cost_class: 2.0
              cost_bbox: 5.0
              cost_giou: 2.0
              cost_class_type: focal_loss_cost
              focal cost alpha: 0.25
              focal cost gamma: 2.0
          matcher_stage1: Matcher Stage1Assigner
              training: False
              positive_fraction: 0.5
              batch_size_per_image: 256
              k: 4
              t_low: 0.3
              t_high: 0.7
              anchor_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd56d490>
          matcher_stage2: Matcher Stage2Assigner
              training: False
              positive_fraction: 0.25
              num_classes: 601
              batch_size_per_image: 900
              proposal_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd5661f0>
              k: 4
          losses: ['class', 'boxes', 'masks']
          loss_class_type: focal_loss
          weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_mask': 5, 'loss_dice': 5, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_mask_0': 5, 'loss_dice_0': 5, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_mask_1': 5, 'loss_dice_1': 5, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_mask_2': 5, 'loss_dice_2': 5, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_mask_3': 5, 'loss_dice_3': 5, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_mask_4': 5, 'loss_dice_4': 5, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0, 'loss_mask_enc': 5, 'loss_dice_enc': 5}
          num_classes: 601
          eos_coef: 0.1
          focal loss alpha: 0.25
          focal loss gamma: 2.0
          use_fed_loss: True
          fed_loss_num_classes: 50
      (3): Criterion DeformableCriterion
          matcher: Matcher HungarianMatcher
              cost_class: 2.0
              cost_bbox: 5.0
              cost_giou: 2.0
              cost_class_type: focal_loss_cost
              focal cost alpha: 0.25
              focal cost gamma: 2.0
          matcher_stage1: Matcher Stage1Assigner
              training: False
              positive_fraction: 0.5
              batch_size_per_image: 256
              k: 4
              t_low: 0.3
              t_high: 0.7
              anchor_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd5663d0>
          matcher_stage2: Matcher Stage2Assigner
              training: False
              positive_fraction: 0.25
              num_classes: 256
              batch_size_per_image: 900
              proposal_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd672e80>
              k: 4
          losses: ['class', 'boxes', 'masks']
          loss_class_type: focal_loss
          weight_dict: {'loss_class': 1.0, 'loss_bbox': 0.0, 'loss_giou': 0.0, 'loss_mask': 0.0, 'loss_dice': 0.0, 'loss_class_0': 1.0, 'loss_bbox_0': 0.0, 'loss_giou_0': 0.0, 'loss_mask_0': 0.0, 'loss_dice_0': 0.0, 'loss_class_1': 1.0, 'loss_bbox_1': 0.0, 'loss_giou_1': 0.0, 'loss_mask_1': 0.0, 'loss_dice_1': 0.0, 'loss_class_2': 1.0, 'loss_bbox_2': 0.0, 'loss_giou_2': 0.0, 'loss_mask_2': 0.0, 'loss_dice_2': 0.0, 'loss_class_3': 1.0, 'loss_bbox_3': 0.0, 'loss_giou_3': 0.0, 'loss_mask_3': 0.0, 'loss_dice_3': 0.0, 'loss_class_4': 1.0, 'loss_bbox_4': 0.0, 'loss_giou_4': 0.0, 'loss_mask_4': 0.0, 'loss_dice_4': 0.0, 'loss_class_enc': 0.0, 'loss_bbox_enc': 0.0, 'loss_giou_enc': 0.0, 'loss_mask_enc': 0.0, 'loss_dice_enc': 0.0}
          num_classes: 256
          eos_coef: 0.1
          focal loss alpha: 0.25
          focal loss gamma: 2.0
          use_fed_loss: False
          fed_loss_num_classes: 50
      (4): Criterion DeformableCriterion
          matcher: Matcher HungarianMatcher
              cost_class: 2.0
              cost_bbox: 5.0
              cost_giou: 2.0
              cost_class_type: focal_loss_cost
              focal cost alpha: 0.25
              focal cost gamma: 2.0
          matcher_stage1: Matcher Stage1Assigner
              training: False
              positive_fraction: 0.5
              batch_size_per_image: 256
              k: 4
              t_low: 0.3
              t_high: 0.7
              anchor_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd672af0>
          matcher_stage2: Matcher Stage2Assigner
              training: False
              positive_fraction: 0.25
              num_classes: 1
              batch_size_per_image: 900
              proposal_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd54b520>
              k: 4
          losses: ['class', 'boxes', 'masks']
          loss_class_type: focal_loss
          weight_dict: {'loss_class': 0.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_mask': 5, 'loss_dice': 5, 'loss_class_0': 0.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_mask_0': 5, 'loss_dice_0': 5, 'loss_class_1': 0.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_mask_1': 5, 'loss_dice_1': 5, 'loss_class_2': 0.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_mask_2': 5, 'loss_dice_2': 5, 'loss_class_3': 0.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_mask_3': 5, 'loss_dice_3': 5, 'loss_class_4': 0.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_mask_4': 5, 'loss_dice_4': 5, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0, 'loss_mask_enc': 5, 'loss_dice_enc': 5}
          num_classes: 1
          eos_coef: 0.1
          focal loss alpha: 0.25
          focal loss gamma: 2.0
          use_fed_loss: False
          fed_loss_num_classes: 50
      (5): Criterion DeformableCriterion
          matcher: Matcher HungarianMatcher
              cost_class: 2.0
              cost_bbox: 5.0
              cost_giou: 2.0
              cost_class_type: focal_loss_cost
              focal cost alpha: 0.25
              focal cost gamma: 2.0
          matcher_stage1: Matcher Stage1Assigner
              training: False
              positive_fraction: 0.5
              batch_size_per_image: 256
              k: 4
              t_low: 0.3
              t_high: 0.7
              anchor_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd54beb0>
          matcher_stage2: Matcher Stage2Assigner
              training: False
              positive_fraction: 0.25
              num_classes: 256
              batch_size_per_image: 900
              proposal_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fda9448e340>
              k: 4
          losses: ['class', 'boxes', 'masks']
          loss_class_type: focal_loss
          weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_mask': 5, 'loss_dice': 5, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_mask_0': 5, 'loss_dice_0': 5, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_mask_1': 5, 'loss_dice_1': 5, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_mask_2': 5, 'loss_dice_2': 5, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_mask_3': 5, 'loss_dice_3': 5, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_mask_4': 5, 'loss_dice_4': 5, 'loss_class_enc': 0.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0, 'loss_mask_enc': 5, 'loss_dice_enc': 5}
          num_classes: 256
          eos_coef: 0.1
          focal loss alpha: 0.25
          focal loss gamma: 2.0
          use_fed_loss: False
          fed_loss_num_classes: 50
      (6): Criterion DeformableCriterion
          matcher: Matcher HungarianMatcher
              cost_class: 2.0
              cost_bbox: 5.0
              cost_giou: 2.0
              cost_class_type: focal_loss_cost
              focal cost alpha: 0.25
              focal cost gamma: 2.0
          matcher_stage1: Matcher Stage1Assigner
              training: False
              positive_fraction: 0.5
              batch_size_per_image: 256
              k: 4
              t_low: 0.3
              t_high: 0.7
              anchor_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fda9448e520>
          matcher_stage2: Matcher Stage2Assigner
              training: False
              positive_fraction: 0.25
              num_classes: 256
              batch_size_per_image: 900
              proposal_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fda94495280>
              k: 4
          losses: ['class', 'boxes', 'masks']
          loss_class_type: focal_loss
          weight_dict: {'loss_class': 1.0, 'loss_bbox': 0.0, 'loss_giou': 0.0, 'loss_mask': 0.0, 'loss_dice': 0.0, 'loss_class_0': 1.0, 'loss_bbox_0': 0.0, 'loss_giou_0': 0.0, 'loss_mask_0': 0.0, 'loss_dice_0': 0.0, 'loss_class_1': 1.0, 'loss_bbox_1': 0.0, 'loss_giou_1': 0.0, 'loss_mask_1': 0.0, 'loss_dice_1': 0.0, 'loss_class_2': 1.0, 'loss_bbox_2': 0.0, 'loss_giou_2': 0.0, 'loss_mask_2': 0.0, 'loss_dice_2': 0.0, 'loss_class_3': 1.0, 'loss_bbox_3': 0.0, 'loss_giou_3': 0.0, 'loss_mask_3': 0.0, 'loss_dice_3': 0.0, 'loss_class_4': 1.0, 'loss_bbox_4': 0.0, 'loss_giou_4': 0.0, 'loss_mask_4': 0.0, 'loss_dice_4': 0.0, 'loss_class_enc': 0.0, 'loss_bbox_enc': 0.0, 'loss_giou_enc': 0.0, 'loss_mask_enc': 0.0, 'loss_dice_enc': 0.0}
          num_classes: 256
          eos_coef: 0.1
          focal loss alpha: 0.25
          focal loss gamma: 2.0
          use_fed_loss: False
          fed_loss_num_classes: 50
      (7): Criterion DeformableCriterion
          matcher: Matcher HungarianMatcher
              cost_class: 2.0
              cost_bbox: 5.0
              cost_giou: 2.0
              cost_class_type: focal_loss_cost
              focal cost alpha: 0.25
              focal cost gamma: 2.0
          matcher_stage1: Matcher Stage1Assigner
              training: False
              positive_fraction: 0.5
              batch_size_per_image: 256
              k: 4
              t_low: 0.3
              t_high: 0.7
              anchor_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fda94495460>
          matcher_stage2: Matcher Stage2Assigner
              training: False
              positive_fraction: 0.25
              num_classes: 256
              batch_size_per_image: 900
              proposal_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fda9448e0a0>
              k: 4
          losses: ['class', 'boxes', 'masks']
          loss_class_type: focal_loss
          weight_dict: {'loss_class': 1.0, 'loss_bbox': 0.0, 'loss_giou': 0.0, 'loss_mask': 0.0, 'loss_dice': 0.0, 'loss_class_0': 1.0, 'loss_bbox_0': 0.0, 'loss_giou_0': 0.0, 'loss_mask_0': 0.0, 'loss_dice_0': 0.0, 'loss_class_1': 1.0, 'loss_bbox_1': 0.0, 'loss_giou_1': 0.0, 'loss_mask_1': 0.0, 'loss_dice_1': 0.0, 'loss_class_2': 1.0, 'loss_bbox_2': 0.0, 'loss_giou_2': 0.0, 'loss_mask_2': 0.0, 'loss_dice_2': 0.0, 'loss_class_3': 1.0, 'loss_bbox_3': 0.0, 'loss_giou_3': 0.0, 'loss_mask_3': 0.0, 'loss_dice_3': 0.0, 'loss_class_4': 1.0, 'loss_bbox_4': 0.0, 'loss_giou_4': 0.0, 'loss_mask_4': 0.0, 'loss_dice_4': 0.0, 'loss_class_enc': 0.0, 'loss_bbox_enc': 0.0, 'loss_giou_enc': 0.0, 'loss_mask_enc': 0.0, 'loss_dice_enc': 0.0}
          num_classes: 256
          eos_coef: 0.1
          focal loss alpha: 0.25
          focal loss gamma: 2.0
          use_fed_loss: False
          fed_loss_num_classes: 50
      (8): Criterion DeformableCriterion
          matcher: Matcher HungarianMatcher
              cost_class: 2.0
              cost_bbox: 5.0
              cost_giou: 2.0
              cost_class_type: focal_loss_cost
              focal cost alpha: 0.25
              focal cost gamma: 2.0
          matcher_stage1: Matcher Stage1Assigner
              training: False
              positive_fraction: 0.5
              batch_size_per_image: 256
              k: 4
              t_low: 0.3
              t_high: 0.7
              anchor_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fda9448e250>
          matcher_stage2: Matcher Stage2Assigner
              training: False
              positive_fraction: 0.25
              num_classes: 256
              batch_size_per_image: 900
              proposal_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd56d130>
              k: 4
          losses: ['class', 'boxes', 'masks']
          loss_class_type: focal_loss
          weight_dict: {'loss_class': 1.0, 'loss_bbox': 0.0, 'loss_giou': 0.0, 'loss_mask': 0.0, 'loss_dice': 0.0, 'loss_class_0': 1.0, 'loss_bbox_0': 0.0, 'loss_giou_0': 0.0, 'loss_mask_0': 0.0, 'loss_dice_0': 0.0, 'loss_class_1': 1.0, 'loss_bbox_1': 0.0, 'loss_giou_1': 0.0, 'loss_mask_1': 0.0, 'loss_dice_1': 0.0, 'loss_class_2': 1.0, 'loss_bbox_2': 0.0, 'loss_giou_2': 0.0, 'loss_mask_2': 0.0, 'loss_dice_2': 0.0, 'loss_class_3': 1.0, 'loss_bbox_3': 0.0, 'loss_giou_3': 0.0, 'loss_mask_3': 0.0, 'loss_dice_3': 0.0, 'loss_class_4': 1.0, 'loss_bbox_4': 0.0, 'loss_giou_4': 0.0, 'loss_mask_4': 0.0, 'loss_dice_4': 0.0, 'loss_class_enc': 0.0, 'loss_bbox_enc': 0.0, 'loss_giou_enc': 0.0, 'loss_mask_enc': 0.0, 'loss_dice_enc': 0.0}
          num_classes: 256
          eos_coef: 0.1
          focal loss alpha: 0.25
          focal loss gamma: 2.0
          use_fed_loss: False
          fed_loss_num_classes: 50
      (9): Criterion DeformableCriterion
          matcher: Matcher HungarianMatcher
              cost_class: 2.0
              cost_bbox: 5.0
              cost_giou: 2.0
              cost_class_type: focal_loss_cost
              focal cost alpha: 0.25
              focal cost gamma: 2.0
          matcher_stage1: Matcher Stage1Assigner
              training: False
              positive_fraction: 0.5
              batch_size_per_image: 256
              k: 4
              t_low: 0.3
              t_high: 0.7
              anchor_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd56d040>
          matcher_stage2: Matcher Stage2Assigner
              training: False
              positive_fraction: 0.25
              num_classes: 256
              batch_size_per_image: 900
              proposal_matcher: <ape.modeling.ape_deta.assigner.Matcher object at 0x7fdacd566910>
              k: 4
          losses: ['class', 'boxes', 'masks']
          loss_class_type: focal_loss
          weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_mask': 5, 'loss_dice': 5, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_mask_0': 5, 'loss_dice_0': 5, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_mask_1': 5, 'loss_dice_1': 5, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_mask_2': 5, 'loss_dice_2': 5, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_mask_3': 5, 'loss_dice_3': 5, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_mask_4': 5, 'loss_dice_4': 5, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0, 'loss_mask_enc': 5, 'loss_dice_enc': 5}
          num_classes: 256
          eos_coef: 0.1
          focal loss alpha: 0.25
          focal loss gamma: 2.0
          use_fed_loss: False
          fed_loss_num_classes: 50
    )
    (class_embed): ModuleList(
      (0-5): 6 x VisionLanguageAlign(
        (dot_product_projection_image): Identity()
        (dot_product_projection_text): Linear(in_features=1024, out_features=256, bias=True)
      )
      (6): Linear(in_features=256, out_features=1, bias=True)
    )
    (lateral_conv): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (output_conv): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
    )
    (mask_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (mask_embed): MLP(
      (layers): ModuleList(
        (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
      )
    )
    (model_language): EVA02CLIP(
      (net): CustomCLIP(
        (text): TextTransformer(
          (token_embedding): Embedding(49408, 1280)
          (transformer): Transformer(
            (resblocks): ModuleList(
              (0-31): 32 x ResidualAttentionBlock(
                (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
                )
                (ls_1): Identity()
                (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
                  (gelu): GELU(approximate='none')
                  (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
                )
                (ls_2): Identity()
              )
            )
          )
          (ln_final): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
)
